---
title: "Untitled"
author: "takuya furusawa"
date: "2022/3/13"
output:
   pdf_document:
    latex_engine: xelatex
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r include=FALSE}
library(tinytex)
library(dplyr)
library(tidyverse)
```

# 9 Use data from the hotspots experiment in Table 8.4 and the probabilities that each unit is exposed to immediate or spillover treatments (Table 8.5) to answer the following questions:
```{r}
data<-read.csv("GerberGreenBook_Chapter8_Table_8_4_8_5.csv")

```
## (a) For the subset of 11 hotspot locations that lie outside the range of possible spillovers,calculate $E[Y_{01}-Y_{00}]$, the ATE of immediate police surveillance.
```{r}
data_remote<-filter(data,prob10==0)
Y01_00_remote<-mean(data_remote$y01)-mean(data_remote$y00)
```

$$
E[Y_{01}-Y_{00}]=`r Y01_00_remote`
$$

## (b) For the remaining 19 hotspot locations that lie within the range of possible spillovers, calculate $E[Y_{01}-Y_{00}]$,$E[Y_{10}-Y_{00}]$, and $E[Y_{11}-Y_{00}]$.

```{r}
# Remaining hotspots is...
data_close<-filter(data,prob10!=0)


# E[Y_01-Y_00]
Y01_00<-mean(data_close$y01)-mean(data_close$y00)

# E[Y_10-Y_00]
Y10_00<-mean(data_close$y10)-mean(data_close$y00)

# E[Y_11-Y_00]
Y11_00<-mean(data_close$y11)-mean(data_close$y00)
```
**Confirming the number of the remaining hotspots.**
$`r nrow(data_close)`$ hotspots remain.

**Average effects are...**
$$\begin{aligned}
E[Y_{01}-Y_{00}]=`r Y01_00`
\\E[Y_{10}-Y_{00}]=`r Y10_00`
\\E[Y_{11}-Y_{00}]=`r Y11_00`
\end{aligned}$$

## (c) Use the data at http://isps.research.yale.edu/FEDAI to estimate the average effect of spillover on nonexperimental units. Note that your estimator must make use of the probability that each unit lies within 500 meters of a treated experimental unit; exclude from your analysis any units that have zero probability of experiencing spillovers.
```{r}
non<-read.csv("GerberGreenBook_Chapter8_Exercise_9c.csv.csv")

# Excluding zero probability
non<-filter(non,prob10==0)

Y10_00_non<-mean(non$y10)-mean(non$y00)
```

$$
E[Y_{01}-Y_{00}]=`r Y10_00_non`
$$

# 3 Maximum Likelihood Estimation: Suppose that we observe the following independent data:

```{r}
y<-c(10,4,5,3,9,2,7,3,6,4)
```

## (a)Plot the log-likelihood function using the Poisson distribution
Given $Pr(X=k)=\frac{\lambda^{k}e^{-\lambda}}{k!}$, the likelihood function using the Poisson distribution is...
$$
\frac{\lambda^{y_1}e^{-\lambda}}{y_1!} \times \frac{\lambda^{y_2}e^{-\lambda}}{y_2!} \times ...\times \frac{\lambda^{y_n}e^{-\lambda}}{y_n!}
=\prod_{i=1}^{n}\frac{\lambda^{y_i}e^{-\lambda}}{y_i!}
$$

Taking the log, we have
$$
L_n(\lambda)=
log(\prod_{i=1}^{n}\frac{\lambda^{y_i}e^{-\lambda}}{y_i!})=log(\prod_{i=1}^{n}\frac{\lambda^{y_i}}{y_i!})+log(e^{-\lambda})
=-n\lambda+\sum_{i=1}^{n}log\frac{\lambda^{y_i}}{y_i!}
$$
```{r}
# 1. write a function for the log-likelihood
# with lambda as the input
log.lik <- function(lambda) {
  n<-length(y)
  # calculating the contents of Sigma.
  results<-rep(NA,n) # vector of them
  
  for(i in 1:n){
      y_i<-y[i]
    results[i]<-log(lambda^y_i/gamma(y_i+1))
  }
  out<-sum(results)-n*lambda
  return(out)
}

# 2. generate a vector with the possible values of lambda
p.l <- seq(0,30,0.1)

# 3. plot the log likelihood function

plot(p.l, lapply(p.l, log.lik))
```
## Looking at the plot, what does the maximum appear to be?
Let denote $\hat \lambda$ as the most likely value of lambda generating the observed independent data, $y$.
The maximum value shows the probability that $\hat\lambda$ generates the set of the observed data, $y$.

## (b) Now use R to solve for the MLE. There are a variety of commands you can use (you can check optim or optimize, for example). Below is some example code using optim.

**Use "optimize" function**
```{r}
mle<-optimize(log.lik, interval = c(0, 30),  maximum = TRUE,tol = 0.000001)
```
MLE is `r mle$maximum``

**Check with "optim" function**
```{r}
mle <- optim(
c(1), # starting value to look for max

log.lik, # the function we are optimizing

control=list(fnscale=-1), # this tells optim to maximize (vs minimize)

lower=0, # lower bound for optimization
upper=100, # upper bound

method="Brent" # one dimensional optimization method

)

```

$$
\hat\lambda=`r mle$par`
$$

## (c) Now compare the MLE estimate of Î» to the mean of y. Interpret your results.
```{r}
m<-mean(y)
```
$$
\overline{y}=`r m`
$$
We can make sure that MLE is equal to the everage of $y$.